{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997b7249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from data_download import MAttackDataPreparator\n",
    "\n",
    "# current dir\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0887a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir for dataset\n",
    "m_attack_data_path = Path(cwd).parent / \"M-Attack-VLM\"\n",
    "\n",
    "# global parameters\n",
    "dataset = \"bigscale_100\"\n",
    "variations=[\"4\", \"8\", \"16\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a49369",
   "metadata": {},
   "source": [
    "## Option №1 - just download before you start llamator attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba82055",
   "metadata": {},
   "source": [
    "In normal cicumstances, download must be handled automatically. But sometimes there is a small chance for the error with dataset lib. So it's useful to have some options to get things done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d4171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = MAttackDataPreparator(base_path=m_attack_data_path,\n",
    "                             dataset=dataset)\n",
    "prep.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3019ad",
   "metadata": {},
   "source": [
    "## Option №2 - check how it looks in attack, save in format needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48708c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# how it looks inside attack\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def imgpath2base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "    return encoded_string\n",
    "\n",
    "\n",
    "def _load_attack_data(dataset: str, dataset_variations: list) -> pd.DataFrame:\n",
    "    base_dir = Path(cwd).parent\n",
    "    \n",
    "    m_attack_data_path = base_dir / \"M-Attack-VLM\"\n",
    "    input_data_path = m_attack_data_path / dataset\n",
    "\n",
    "    # download if no file found\n",
    "    missing = [str(input_data_path / v) for v in dataset_variations if not (input_data_path / v).exists()]\n",
    "    if missing:\n",
    "        logger.warning(f\"[WARN] Missing variations found: {missing}\")\n",
    "        logger.info(f\"[INFO] Triggering M-Attack data download...\")\n",
    "        prep = MAttackDataPreparator(base_path=m_attack_data_path, dataset=dataset)\n",
    "        prep.prepare(variations=dataset_variations)\n",
    "\n",
    "    # load targets\n",
    "    target_data_path = m_attack_data_path / \"target\" / dataset\n",
    "    df_keywords = pd.read_json(target_data_path / \"keywords.json\")\n",
    "    df_captions = pd.read_json(target_data_path / \"caption.json\")\n",
    "    df_target = df_keywords.merge(df_captions, on=\"image\")\n",
    "    \n",
    "    df_target[\"image_id\"] = df_target[\"image\"].apply(lambda x: int(Path(x).stem))\n",
    "\n",
    "    data = []\n",
    "    for dataset_variation in dataset_variations:\n",
    "        attack_data_path = input_data_path / dataset_variation\n",
    "        if not attack_data_path.exists():\n",
    "            logger.warning(f\"[WARN] Skipping {attack_data_path} — folder does not exist.\")\n",
    "            continue\n",
    "\n",
    "        files = list(attack_data_path.glob(\"*.png\"))\n",
    "        if not files:\n",
    "            logger.warning(f\"[WARN] No PNGs found in {attack_data_path}\")\n",
    "            continue\n",
    "\n",
    "        logger.info(f\"[INFO] Processing {len(files)} files from {attack_data_path}\")\n",
    "        for file in files:\n",
    "            try:\n",
    "                image_encoded = imgpath2base64(file)\n",
    "                image_id = int(file.stem)\n",
    "                data.append(\n",
    "                    dict(\n",
    "                        image_path=str(file.relative_to(m_attack_data_path.parent)),\n",
    "                        image_id=image_id,\n",
    "                        dataset_variation=dataset_variation,\n",
    "                        image_encoded=image_encoded,\n",
    "                    )\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logger.error(f\"[ERROR] Failed to encode {file.name}: {e}\")\n",
    "\n",
    "    if not data:\n",
    "        raise RuntimeError(\"No image data collected — check folder structure and file presence.\")\n",
    "\n",
    "    df_data = pd.DataFrame(data)\n",
    "    \n",
    "    df_data[\"image_id\"] = df_data[\"image_id\"].astype(int)\n",
    "    df_target[\"image_id\"] = df_target[\"image_id\"].astype(int)\n",
    "    \n",
    "    df_attack = df_data.merge(\n",
    "        df_target, on=\"image_id\", how=\"left\")\n",
    "\n",
    "    df_attack[\"image_id\"] = df_attack[\"image_id\"].astype(int)\n",
    "    df_attack = df_attack.sort_values([\"image_id\", \"dataset_variation\"])\n",
    "    \n",
    "    logger.info(f\"[INFO] Final dataset: {len(df_attack)} matched samples.\")\n",
    "    return df_attack.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f15b50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"bigscale_100\"\n",
    "variations=[\"4\", \"8\", \"16\"]\n",
    "\n",
    "result = _load_attack_data(dataset, variations)\n",
    "\n",
    "print(result.shape)\n",
    "\n",
    "result.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bea770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.to_parquet(\"llm_m_attack_prepared.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91267f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b06a94b7",
   "metadata": {},
   "source": [
    "## Option 3 - load existing parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac3692c",
   "metadata": {},
   "source": [
    "note, that there are just 4 images on different epsilon, it's more like demo version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ceb6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(Path(cwd).parent / \"llm_m_attack_prepared.parquet\")\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1a8676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
